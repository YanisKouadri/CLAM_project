{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec4d91d-d3ce-4017-9040-e51b325c581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_labels_path = '/media/yanis/LaCie/Final_execution_files/train/kfolds_csv/'\n",
    "features_path = '/media/yanis/LaCie/Final_execution_files/train/features_final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e6770e-6e0b-457b-bb8e-6242a7897921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def generate_stratified_kfold_splits(directory_path,output_path, k=5):\n",
    "    filenames = [f for f in os.listdir(directory_path) if f.endswith('.pt')]\n",
    "    slide_ids = ['_'.join(filename.split('_')[:2]) for filename in filenames]\n",
    "\n",
    "    labels = []\n",
    "    for slide_id in slide_ids:\n",
    "        if 'normal' in slide_id:\n",
    "            label = 'normal_tissue'\n",
    "        elif 'tumor' in slide_id:\n",
    "            label = 'tumor_tissue'\n",
    "        labels.append(label)\n",
    "\n",
    "    df = pd.DataFrame({'slide_id': slide_ids, 'label': labels})\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold = 1\n",
    "\n",
    "    for train_index, val_index in skf.split(df, df['label']):\n",
    "        train_df, val_df = df.iloc[train_index], df.iloc[val_index]\n",
    "        \n",
    "        train_df['split_membership'] = 'train'\n",
    "        val_df['split_membership'] = 'val'\n",
    "        \n",
    "        fold_df = pd.concat([train_df, val_df]).sort_values(by='slide_id')\n",
    "        \n",
    "        fold_csv_output_path = os.path.join(output_path, f'fold_{fold}_split.csv')\n",
    "        fold_df.to_csv(fold_csv_output_path, index=False)\n",
    "        fold += 1\n",
    "\n",
    "directory_path = features_path\n",
    "\n",
    "generate_stratified_kfold_splits(directory_path,wsi_labels_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8fa1d71-9254-49f1-a168-8efdb346e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "class WSI_dataset(Dataset):\n",
    "    def __init__(self,wsi_list,features_path):\n",
    "        self.wsi_list = wsi_list\n",
    "        self.features_path = features_path\n",
    "        self.label_to_int = {'normal_tissue': 0, 'tumor_tissue': 1}\n",
    "    def __len__(self):\n",
    "        return len(self.wsi_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.wsi_list[idx]['slide_id']\n",
    "        label = torch.tensor(self.label_to_int[self.wsi_list[idx]['label']], dtype=torch.long)\n",
    "        features = torch.load(self.features_path+name+'_features.pt')\n",
    "        return (features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10cf3ded-7b1a-4883-83e1-a0df903047b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_combined_loss(train_loss_values, val_loss_values, epochs):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.plot(epochs, train_loss_values, label='Train Loss', color='blue')\n",
    "\n",
    "    # Plot validation loss\n",
    "    plt.plot(epochs, val_loss_values, label='Validation Loss', color='red')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf0e375-30a0-45a6-9a4d-e2eed59cef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_all_csv_from_directory(directory_path):\n",
    "    csv_files = [f for f in os.listdir(directory_path) if f.endswith('.csv')]\n",
    "    csv_dfs = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        csv_dfs.append(df)\n",
    "\n",
    "    return csv_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77f4065-65e4-49d9-864c-3c90457a4178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 0\n",
      "Setting tau to 1.0\n",
      "Loss hasn't improved for more than 5 epochs - early stopping at epoch 25\n",
      "Model 0done, Best epoch :  19 \n",
      ",Loss from best epoch: 0.4887163035571575 \n",
      "ROC-AUC from best epoch :  0.83\n",
      "Starting fold 1\n",
      "Setting tau to 1.0\n",
      "Loss hasn't improved for more than 5 epochs - early stopping at epoch 33\n",
      "Model 1done, Best epoch :  27 \n",
      ",Loss from best epoch: 0.2955414322670549 \n",
      "ROC-AUC from best epoch :  0.9500000000000001\n",
      "Starting fold 2\n",
      "Setting tau to 1.0\n",
      "Loss hasn't improved for more than 5 epochs - early stopping at epoch 22\n",
      "Model 2done, Best epoch :  16 \n",
      ",Loss from best epoch: 0.5497371047735214 \n",
      "ROC-AUC from best epoch :  0.81\n",
      "Starting fold 3\n",
      "Setting tau to 1.0\n",
      "Loss hasn't improved for more than 5 epochs - early stopping at epoch 26\n",
      "Model 3done, Best epoch :  20 \n",
      ",Loss from best epoch: 0.3736212524144273 \n",
      "ROC-AUC from best epoch :  0.9444444444444444\n",
      "Starting fold 4\n",
      "Setting tau to 1.0\n",
      "Loss hasn't improved for more than 5 epochs - early stopping at epoch 24\n",
      "Model 4done, Best epoch :  18 \n",
      ",Loss from best epoch: 0.4527982924329607 \n",
      "ROC-AUC from best epoch :  0.9111111111111112\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from models.model_clam import CLAM_SB\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from topk.svm import SmoothTop1SVM\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "folds_list = load_all_csv_from_directory(wsi_labels_path)\n",
    "model_perf = []\n",
    "\n",
    "for k,wsi_dataframe in enumerate(folds_list):\n",
    "    print('Starting fold',k)\n",
    "    wsi_df = wsi_dataframe\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "    \n",
    "    for _, row in wsi_df.iterrows():\n",
    "        membership = row['split_membership']\n",
    "        if membership == 'train':\n",
    "            train_list.append(row)\n",
    "        elif membership == 'val':\n",
    "            val_list.append(row)\n",
    "            \n",
    "    train_dataset,val_dataset = WSI_dataset(train_list,features_path),WSI_dataset(val_list,features_path)\n",
    "    batch_size = 1\n",
    "    shuffle = True\n",
    "    num_workers = 4\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    instance_loss_fn = SmoothTop1SVM(n_classes = 2).cuda()\n",
    "    \n",
    "    model_dict = {\"dropout\": True, 'n_classes': 2,\"size_arg\": 'small','k_sample': 8}\n",
    "    \n",
    "    model = CLAM_SB(**model_dict, instance_loss_fn=instance_loss_fn)\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0002, weight_decay=1e-5)\n",
    "    \n",
    "    model.relocate() #met le modele sur le device (gpu)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    bag_weight = 0.7\n",
    "    num_epochs = 50\n",
    "    \n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    best_f1 = 0\n",
    "    best_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.\n",
    "        val_loss = 0.\n",
    "        #print('starting epoch ',epoch)\n",
    "        model.train()\n",
    "        for index, (features, label) in enumerate(train_loader):\n",
    "            #print('starting batch ',index)\n",
    "            features = features.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            logits, Y_prob, pred, _, instance_dict = model(features, label=label, instance_eval=True)\n",
    "            loss = loss_fn(logits, label)\n",
    "            instance_loss = instance_dict['instance_loss']\n",
    "            total_loss = bag_weight * loss + (1-bag_weight) * instance_loss \n",
    "            train_loss += loss.item()\n",
    "            total_loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        train_loss /= len(train_loader)\n",
    "        #print('Epoch: {}, train_loss: {:.4f}'.format(epoch, train_loss))\n",
    "        model.eval()\n",
    "        all_preds_prob = []\n",
    "        all_labels = []\n",
    "        for index, (features, label) in enumerate(val_loader):\n",
    "            #print('starting batch ',index)\n",
    "            features = features.to(device)\n",
    "            label = label.to(device)\n",
    "            with torch.no_grad():\n",
    "                logits, Y_prob, Y_hat, _, instance_dict = model(features, label=label, instance_eval=False)\n",
    "                loss = loss_fn(logits, label)\n",
    "                val_loss += loss.item()\n",
    "                all_preds_prob.append(Y_prob[0][1].cpu())\n",
    "                all_labels.append(label.cpu())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        fpr, tpr, thresholds = roc_curve(all_labels, all_preds_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        #print('Epoch: {}, val_loss: {:.4f}, AUC: {:.2f}, accuracy: {:.2f}, precision: {:.2f}, recall: {:.2f}, f1: {:.2f}'.format(epoch, val_loss, roc_auc,total_acc, precision, recall, f1))\n",
    "        if val_loss < best_loss:\n",
    "                model_path = './CLAM_fold_'+str(k)+'.pt'\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                best_roc_auc = roc_auc\n",
    "                best_loss = val_loss\n",
    "                best_epoch = epoch\n",
    "                early_stopping_counter = 0\n",
    "        \n",
    "        else:\n",
    "            early_stopping_counter+=1\n",
    "            if(early_stopping_counter>5):\n",
    "                print(\"Loss hasn't improved for more than 5 epochs - early stopping at epoch\",epoch)\n",
    "                break\n",
    "    \n",
    "           \n",
    "    print('Model '+str(k)+' done, Best epoch : ',best_epoch,'\\nLoss from best epoch:',best_loss,'\\nROC-AUC from best epoch : ',best_roc_auc)\n",
    "    model_perf.append([best_loss,best_roc_auc])\n",
    "    #plot_combined_loss(train_loss_list, val_loss_list, range(0,epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10855ea9-0273-4c2a-b60b-c469e6ba89d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.4887163035571575, 0.83],\n",
       " [0.2955414322670549, 0.9500000000000001],\n",
       " [0.5497371047735214, 0.81],\n",
       " [0.3736212524144273, 0.9444444444444444],\n",
       " [0.4527982924329607, 0.9111111111111112]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d12fa3b3-0c32-44ae-a3c7-87ed83e1aebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with the smallest loss : model  1\n",
      "Mean ROC-AUC: 0.89\n"
     ]
    }
   ],
   "source": [
    "min_first_element_index = min(range(len(model_perf)), key=lambda i: model_perf[i][0])\n",
    "print(\"Model with the smallest loss : model \", min_first_element_index)\n",
    "\n",
    "mean_second_elements = sum(sublist[1] for sublist in model_perf) / len(model_perf)\n",
    "print(\"Mean ROC-AUC: {:.2f}\".format(mean_second_elements))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
